name: Test Pipeline

on:
  pull_request:
    branches: [ main, develop ]
  push:
    branches: [ main, develop ]
  workflow_dispatch:

env:
  BACKEND_URL: http://localhost:8080

jobs:
  promptfoo-tests:
    name: Promptfoo Evaluations
    runs-on: ubuntu-latest
    
    services:
      backend:
        image: maven:3.9-eclipse-temurin-17
        ports:
          - 8080:8080
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Java 17
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'
          cache: 'maven'
      
      - name: Build backend
        working-directory: ./llm
        run: mvn clean package -DskipTests
      
      - name: Start backend service
        working-directory: ./llm
        run: |
          java -jar target/*.jar &
          echo $! > backend.pid
          # Wait for backend to be ready
          timeout 60 bash -c 'until curl -f http://localhost:8080/actuator/health 2>/dev/null; do sleep 2; done'
        env:
          SPRING_AI_OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Run Promptfoo tests
        working-directory: ./promptfoo-tests
        run: |
          npm run eval
        env:
          BACKEND_URL: http://localhost:8080
      
      - name: Upload Promptfoo results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: promptfoo-results
          path: promptfoo-tests/.promptfoo/
          retention-days: 30
      
      - name: Stop backend
        if: always()
        run: |
          if [ -f llm/backend.pid ]; then
            kill $(cat llm/backend.pid) || true
          fi

  deepeval-tests:
    name: Deepeval Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Java 17
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'
          cache: 'maven'
      
      - name: Build backend
        working-directory: ./llm
        run: mvn clean package -DskipTests
      
      - name: Start backend service
        working-directory: ./llm
        run: |
          java -jar target/*.jar &
          echo $! > backend.pid
          # Wait for backend to be ready
          timeout 60 bash -c 'until curl -f http://localhost:8080/actuator/health 2>/dev/null; do sleep 2; done'
        env:
          SPRING_AI_OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        working-directory: ./deepeval-tests
        run: |
          pip install -r requirements.txt
      
      - name: Run Deepeval tests
        working-directory: ./deepeval-tests
        run: |
          pytest -v --tb=short
        env:
          BACKEND_URL: http://localhost:8080
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      
      - name: Upload Deepeval results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: deepeval-results
          path: deepeval-tests/.deepeval/
          retention-days: 30
      
      - name: Stop backend
        if: always()
        run: |
          if [ -f llm/backend.pid ]; then
            kill $(cat llm/backend.pid) || true
          fi

  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [promptfoo-tests, deepeval-tests]
    if: always()
    
    steps:
      - name: Check test results
        run: |
          if [ "${{ needs.promptfoo-tests.result }}" != "success" ] || [ "${{ needs.deepeval-tests.result }}" != "success" ]; then
            echo "❌ Tests failed"
            exit 1
          else
            echo "✅ All tests passed"
          fi
